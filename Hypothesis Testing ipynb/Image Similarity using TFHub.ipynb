{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ec2f0b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as tfhub\n",
    "from PIL import Image, ImageChops\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6be986b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESIZED_DIR = r\"F:\\Minor Data Collection\\Resized Original Image\\BDS\"\n",
    "ORI_DIR = r\"F:\\Minor Data Collection\\All Images\\Resized BDS\"\n",
    "w = 300\n",
    "h = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "85539ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = tf.keras.models.load_model(r\"C:\\Users\\parzi\\OneDrive - Tribhuvan University\\Desktop\\Minor Project\\Monument Detection with CNN\\Monument Object Detection\\Trained Models\\mobilenetv2_300x300_fine-tuned.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "beb485f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imgs_similarity(path_1, path_2):\n",
    "    img1 = Image.open(path_1)\n",
    "    img2 = Image.open(path_2)\n",
    "    img1_tensor = tf.convert_to_tensor(img1)\n",
    "    img2_tensor = tf.convert_to_tensor(img2)\n",
    "    img1_output = trained_model.layers[1]([np.expand_dims(img1_tensor, axis = 0)])\n",
    "    img2_output = trained_model.layers[1]([np.expand_dims(img2_tensor, axis = 0)])\n",
    "    similarity = tf.keras.losses.cosine_similarity(\n",
    "    [img1_output], [img2_output], axis = -1)\n",
    "    img1.close()\n",
    "    img2.close()\n",
    "    return tf.math.reduce_sum(similarity).numpy() / 100.0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0f3f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1487.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|███████████▋                                                                   | 742/5000 [02:22<11:46,  6.03it/s]"
     ]
    }
   ],
   "source": [
    "for resized_img in os.listdir(RESIZED_DIR)[1:]:\n",
    "    abs_score = 0\n",
    "    orig_file_name = ''\n",
    "    print(resized_img)\n",
    "    img1_path = os.path.join(RESIZED_DIR, resized_img)\n",
    "    img1 = Image.open(img1_path)\n",
    "    img1_tensor = tf.convert_to_tensor(img1)\n",
    "    img1_output = trained_model.layers[1]([np.expand_dims(img1_tensor, axis = 0)])\n",
    "    for ori_img in tqdm(os.listdir(ORI_DIR)):\n",
    "        if ori_img.endswith('jpg'):\n",
    "            img2_path = os.path.join(ORI_DIR, ori_img)\n",
    "            img2 = Image.open(img2_path)\n",
    "            img2_tensor = tf.convert_to_tensor(img2)\n",
    "            img2_output = trained_model.layers[1]([np.expand_dims(img2_tensor, axis = 0)])\n",
    "            similarity = tf.keras.losses.cosine_similarity([img1_output], [img2_output], axis = -1)\n",
    "            score = tf.math.reduce_sum(similarity).numpy() / 100.0\n",
    "            if score < 0.0:\n",
    "                if abs(score) > abs_score:\n",
    "                    abs_score = abs(score)\n",
    "                    orig_file_name = ori_img\n",
    "    print(orig_file_name)\n",
    "    print(lowest_value)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "59a01649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32824554443359377\n"
     ]
    }
   ],
   "source": [
    "print(abs_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "403e63eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92add521",
   "metadata": {},
   "source": [
    "### Using Pre-trained mobilenetv2 model from TFHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "add99347",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1_resized_tensor = tf.keras.preprocessing.image.smart_resize(img1_tensor, (224, 224))\n",
    "img2_resized_tensor = tf.keras.preprocessing.image.smart_resize(img2_tensor, (224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20599faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_of_image_1 = tfhub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\", trainable = False)([img1_resized_tensor])\n",
    "feature_of_image_2 = tfhub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\", trainable = False)([img2_resized_tensor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "02adc980",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_of_image_1 = tfhub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\", trainable = False)([img1_resized_tensor])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
