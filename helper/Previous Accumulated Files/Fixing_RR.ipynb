{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c804a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import xml.etree.ElementTree as ET\n",
    "import random\n",
    "random.seed(10)\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f713e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUG_BASE_DIR = r\"F:\\Minor Data Collection\\Final Image Data\\Monument Original 512\\Augmented 512 v1\"\n",
    "ORI_BASE_DIR = r\"F:\\Minor Data Collection\\Final Image Data\\Monument Original 512\\Original Images and Annotations Resized\"\n",
    "\n",
    "IMG_PATH = \"JPEGImages\"\n",
    "ANNO_PATH = \"Annotations\"\n",
    "\n",
    "output_dir = \"./JPEGimagesNew\"\n",
    "output_annotations_dir = \"./AnnotationsNew\"\n",
    "\n",
    "# listing all the images and their annotations\n",
    "img_files = os.listdir(os.path.join(AUG_BASE_DIR, IMG_PATH))\n",
    "try: \n",
    "    img_files.remove('desktop.ini')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# getting the randomly rotated image data\n",
    "def filter_condition(file_name):\n",
    "    split_arr = file_name.split(\"_\")\n",
    "    if(len(split_arr) == 1):\n",
    "        return False\n",
    "    return split_arr[1] == \"RR\"\n",
    "\n",
    "img_files = list(filter(lambda img : filter_condition(img),img_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e06202cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1448/1448 [01:57<00:00, 12.34it/s]\n"
     ]
    }
   ],
   "source": [
    "for img_name_primary in tqdm(img_files):\n",
    "    # get the image name\n",
    "    name_split = img_name_primary.split(\"_\")\n",
    "    image_name = name_split[0] + \".jpg\"\n",
    "    \n",
    "    # Load the image and its annotation\n",
    "    image_path = os.path.join(ORI_BASE_DIR, IMG_PATH, image_name)\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    degree = random.choice(np.concatenate((np.arange(-16, -8, 0.2), np.arange(8, 16, 0.2))))\n",
    "    angle = degree * math.pi / 180\n",
    "    image = tfa.image.rotate(image,angle,\"bilinear\",\"nearest\")\n",
    "    \n",
    "    # Read the annotation file\n",
    "    annotation_path = os.path.join(ORI_BASE_DIR, ANNO_PATH, image_name.replace(\".jpg\",\".xml\"))\n",
    "    tree = ET.parse(annotation_path)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    # Get the size of the image\n",
    "    size = root.find(\"size\")\n",
    "    width = int(size.find(\"width\").text)\n",
    "    height = int(size.find(\"height\").text)\n",
    "\n",
    "    # Perform the rotation on the bounding boxes\n",
    "    for obj in root.iter(\"object\"):\n",
    "        bndbox = obj.find(\"bndbox\")\n",
    "        xmin = int(bndbox.find(\"xmin\").text)\n",
    "        ymin = int(bndbox.find(\"ymin\").text)\n",
    "        xmax = int(bndbox.find(\"xmax\").text)\n",
    "        ymax = int(bndbox.find(\"ymax\").text)\n",
    "\n",
    "        ymin = 512 - ymin\n",
    "        ymax = 512 - ymax\n",
    "\n",
    "        # Find the center of the image\n",
    "        center_x = 256\n",
    "        center_y = 256\n",
    "\n",
    "        # Calculate the new bounding box coordinates\n",
    "        xmin_new = round(center_x + (xmin - center_x) * math.cos(angle) - (ymin - center_y) * math.sin(angle))\n",
    "        ymin_new = round(center_y + (xmin - center_x) * math.sin(angle) + (ymin - center_y) * math.cos(angle))\n",
    "        xmax_new = round(center_x + (xmax - center_x) * math.cos(angle) - (ymax - center_y) * math.sin(angle))\n",
    "        ymax_new = round(center_y + (xmax - center_x) * math.sin(angle) + (ymax - center_y) * math.cos(angle))\n",
    "\n",
    "        ymin_new = 512 - ymin_new\n",
    "        ymax_new = 512 - ymax_new\n",
    "\n",
    "        xmin1 = min([xmin_new,xmax_new])\n",
    "        xmax1 = max([xmin_new,xmax_new])\n",
    "        ymin1 = min([ymin_new,ymax_new])\n",
    "        ymax1 = max([ymin_new,ymax_new])\n",
    "\n",
    "\n",
    "        # changing y by some suitable value ()\n",
    "        if(degree < 0):\n",
    "            xminTemp = xmin + degree\n",
    "            xmaxTemp = xmax - degree\n",
    "            \n",
    "        else:\n",
    "            # calculate factors by which bounding box width might increase            \n",
    "            width_reduce_factor = 0.8 - 0.02 * (degree-10)\n",
    "            reduced_width = width_reduce_factor * (xmax1-xmin1)\n",
    "            center_x = (xmax1 + xmin1)/2\n",
    "            #changing x\n",
    "            xmin1 = round(center_x - reduced_width/2)\n",
    "            xmax1 = round(center_x + reduced_width/2)\n",
    "            xminTemp = min([xmin1,xmax1])\n",
    "            xmaxTemp = max([xmin1,xmax1])\n",
    "\n",
    "        #changing y\n",
    "        reduced_height = (ymax-ymin)-(ymax1-ymin1)\n",
    "        ymin1 = round(ymin1 - reduced_height/2)\n",
    "        ymax1 = round(ymax1 + reduced_height/2)\n",
    "        yminTemp = min([ymin1,ymax1])\n",
    "        ymaxTemp = max([ymin1,ymax1])\n",
    "\n",
    "\n",
    "        # checking if final values are between 0 and 300\n",
    "        dim_arr = [ xminTemp , yminTemp, xmaxTemp, ymaxTemp ]\n",
    "\n",
    "        for y in range(0,4):\n",
    "            i = dim_arr[y]\n",
    "            i = i if i >= 0 else 0\n",
    "            i = i if i <= 512 else 512\n",
    "            dim_arr[y] = round(i)\n",
    "\n",
    "        xmin1 , ymin1, xmax1, ymax1 = dim_arr\n",
    "\n",
    "        # Update the bounding box coordinates in the annotation file\n",
    "        bndbox.find(\"xmin\").text = str(xmin1)\n",
    "        bndbox.find(\"ymin\").text = str(ymin1)\n",
    "        bndbox.find(\"xmax\").text = str(xmax1)\n",
    "        bndbox.find(\"ymax\").text = str(ymax1)\n",
    "    \n",
    "    # chaniging the file name in xml file\n",
    "    filename = root.find('.//filename')\n",
    "    filename.text = img_name_primary.split(\".\")[0] # removing the .jpg in the end\n",
    "\n",
    "    # Save the augmented image\n",
    "    output_image_path = os.path.join(AUG_BASE_DIR, IMG_PATH, img_name_primary)\n",
    "    tf.io.write_file(output_image_path, tf.image.encode_jpeg(image).numpy())\n",
    "\n",
    "    # copy the annotation\n",
    "    output_annotation_path = os.path.join(AUG_BASE_DIR, ANNO_PATH, img_name_primary.replace(\".jpg\",\".xml\"))\n",
    "    tree.write(output_annotation_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0b1a8d",
   "metadata": {},
   "source": [
    "### Handling Tranlation as Above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37035188",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUG_BASE_DIR = r\"F:\\Minor Data Collection\\Final Image Data\\Monument Original 512\\Augmented 512 v1\"\n",
    "ORI_BASE_DIR = r\"F:\\Minor Data Collection\\Final Image Data\\Monument Original 512\\Original Images and Annotations Resized\"\n",
    "\n",
    "IMG_PATH = \"JPEGImages\"\n",
    "ANNO_PATH = \"Annotations\"\n",
    "\n",
    "# listing all the images and their annotations\n",
    "img_files = os.listdir(os.path.join(AUG_BASE_DIR, IMG_PATH))\n",
    "try: \n",
    "    img_files.remove('desktop.ini')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# getting the randomly rotated image data\n",
    "def filter_condition(file_name):\n",
    "    split_arr = file_name.split(\"_\")\n",
    "    if(len(split_arr) == 1):\n",
    "        return False\n",
    "    return split_arr[1] == \"TRAN\"\n",
    "\n",
    "img_files = list(filter(lambda img : filter_condition(img),img_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "256e8738",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                                                                | 7/1330 [00:00<02:18,  9.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function translate at 0x0000013FF7CE2310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▌                                                                               | 10/1330 [00:01<02:02, 10.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function translate at 0x0000013FF7CE2310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1330/1330 [01:50<00:00, 12.00it/s]\n"
     ]
    }
   ],
   "source": [
    "for img_name_primary in tqdm(img_files):\n",
    "    # get the image name\n",
    "    name_split = img_name_primary.split(\"_\")\n",
    "    image_name = name_split[0] + \".jpg\"\n",
    "    \n",
    "    # Load the image and its annotation\n",
    "    image_path = os.path.join(ORI_BASE_DIR, IMG_PATH, image_name)\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "\n",
    "    dx_dy_list = [[40,0],[0,40],[-40,0],[0,-40],[40,40],[-40,-40],[-40,40],[40,-40]]\n",
    "    dx_dy = random.choice(dx_dy_list)\n",
    "    # Perform translation augmentation\n",
    "    image = tfa.image.translate(image, dx_dy,\"bilinear\",\"constant\")\n",
    "\n",
    "    # Read the annotation file\n",
    "    annotation_path = os.path.join(ORI_BASE_DIR, ANNO_PATH, image_name.replace(\".jpg\",\".xml\"))\n",
    "    tree = ET.parse(annotation_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Get the size of the image\n",
    "    size = root.find(\"size\")\n",
    "    width = int(size.find(\"width\").text)\n",
    "    height = int(size.find(\"height\").text)\n",
    "\n",
    "    # Perform the rotation on the bounding boxes\n",
    "    remove = []\n",
    "    for obj in root.iter(\"object\"):\n",
    "        bndbox = obj.find(\"bndbox\")\n",
    "        xmin = int(bndbox.find(\"xmin\").text)\n",
    "        ymin = int(bndbox.find(\"ymin\").text)\n",
    "        xmax = int(bndbox.find(\"xmax\").text)\n",
    "        ymax = int(bndbox.find(\"ymax\").text)\n",
    "\n",
    "        original_width = xmax-xmin\n",
    "        original_height = ymax-ymin\n",
    "\n",
    "        # xmin ymin xmax ymax\n",
    "        dim_arr = [ xmin + dx_dy[0] , ymin + dx_dy[1] , xmax + dx_dy[0], ymax + dx_dy[1] ] \n",
    "        for y in range(0,4):\n",
    "            i = dim_arr[y]\n",
    "            i = i if i >= 0 else 0\n",
    "            i = i if i <= 512 else 512\n",
    "            dim_arr[y] = i\n",
    "\n",
    "        xmin1 , ymin1, xmax1, ymax1 = dim_arr\n",
    "\n",
    "        final_width = xmax1-xmin1\n",
    "        final_height = ymax1-ymin1\n",
    "\n",
    "        # if translated bbox does not retain 50% of it's original width and height then remove it\n",
    "        if( (final_width/original_width) < 0.50 or (final_height/original_height)< 0.50):\n",
    "            root.remove(obj)\n",
    "        else:\n",
    "            # Update the bounding box coordinates in the annotation file\n",
    "            bndbox.find(\"xmin\").text = str(xmin1)\n",
    "            bndbox.find(\"ymin\").text = str(ymin1)\n",
    "            bndbox.find(\"xmax\").text = str(xmax1)\n",
    "            bndbox.find(\"ymax\").text = str(ymax1)\n",
    "\n",
    "\n",
    "    # Save the augmented image\n",
    "    output_image_path = os.path.join(AUG_BASE_DIR, IMG_PATH, img_name_primary)\n",
    "    tf.io.write_file(output_image_path, tf.image.encode_jpeg(image).numpy())\n",
    "\n",
    "    # copy the annotation\n",
    "    output_annotation_path = os.path.join(AUG_BASE_DIR, ANNO_PATH, img_name_primary.replace(\".jpg\",\".xml\"))\n",
    "    tree.write(output_annotation_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1c598e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
